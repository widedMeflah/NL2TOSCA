# üß† NL2TOSCA

**NL2TOSCA** is an open-source dataset designed to evaluate the capability of **Large Language Models (LLMs)** to interpret **natural language (NL) requests** for **cloud service composition** and to generate corresponding **provider-independent TOSCA models**.

This repository accompanies the paper:

> *‚ÄúFrom Natural Language to TOSCA: Leveraging LLMs for Automated Service Composition‚Äù*
> **Wided Meflah et al., ICSOC 2025, Institut Polytechnique de Paris.**

---

## üìÅ Repository Structure

The **NL2TOSCA** repository is organized into two main modules:

---

### **1. Dataset_Generation/**

This directory contains all materials related to the **automatic construction of the NL2TOSCA dataset**.


#### Subdirectories and Files
* **`Dataset/`** ‚Üí Contains the dataset which includes **67 entries**, each structured into six columns:

1. A TOSCA-modeled application
2. A corresponding NL request with low technicality and high completeness (R1)
3. A corresponding NL request with low technicality and low completeness (R2)
4. A corresponding NL request with high technicality and high completeness (R3)
5. A corresponding NL request with high technicality and low completeness (R4)
6. A complexity label (low or high), based on the number of nodes, relationships, and properties

* **`TOSCA-templates/`** ‚Üí Includes the **67 collected TOSCA models**.

* **`prompt_templates.md`** ‚Üí Describes the **prompt templates** used for generating the four types of NL requests (R1‚ÄìR4) based on each TOSCA model.
 
* **`Survey/`** ‚Üí Contains the human evaluation resources for NL request generation.

  * `Survey Responses.csv` ‚Üí The collected responses from participants who rated the quality of generated NL requests.
  * `human_eval_survey_link.md` ‚Üí Contains the link to the human evaluation survey.
---

### **2. Evaluation/**

This directory contains the scripts, metrics, and results used to **evaluate LLMs** on their ability to interpret NL requests and produce accurate TOSCA templates.

#### Subdirectories and Files
* **`evaluation_dataset.xlsx`** ‚Üí Provides the **evaluation dataset**.
* * **`reference_templates_for_evaluation/`** ‚Üí Contains the **ground truth (reference) TOSCA templates** used for comparison.
* * **`generated_templates_for_evaluation/`** ‚Üí Contains the **TOSCA templates generated by LLMs** for  evaluation.
* **`Eval_Metrics/`** ‚Üí Includes the implementation of evaluation metrics such as **F1-score**, **CodeBLEU**, **Tree Edit Distance**, and **Embedding Similarity**.
* **`Results_Evaluation/`** ‚Üí Contains the results of the automatic  evaluations performed on various LLMs.




---


